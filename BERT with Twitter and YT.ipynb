{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "15a3a683-140f-48cd-b278-2ec850cedf08",
      "metadata": {
        "id": "15a3a683-140f-48cd-b278-2ec850cedf08"
      },
      "source": [
        "# YouTube Sentiment Analysis\n",
        "\n",
        "``` yaml\n",
        "original code: https://www.kaggle.com/code/stoicstatic/twitter-sentiment-analysis-for-beginners\n",
        "editor: JiHo Lee\n",
        "last edited: Mar. 19\n",
        "\n",
        "note:\n",
        "- youtube data feature 개수에 맞게 다시 twitter data model을 training 함\n",
        "- 학습된 모델에 youtube data 긁어 온 것으로 테스트\n",
        "- 테스트한 결과 manually label 필요\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8b3f75d-5065-4c56-86d2-2f90129676e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8b3f75d-5065-4c56-86d2-2f90129676e0",
        "outputId": "24b32308-3072-4633-ccfb-c36b21ed2fe1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "# utilities\n",
        "import re\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# plotting\n",
        "import seaborn as sns\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "#additional nltk\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# sklearn\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "#additional sklearn\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2457048d-15d7-43e2-9883-514ec686ee07",
      "metadata": {
        "id": "2457048d-15d7-43e2-9883-514ec686ee07"
      },
      "source": [
        "## Importing dataset\n",
        "\n",
        "The dataset being used is the **sentiment140 dataset**. It contains 1,600,000 tweets extracted using the Twitter API. The tweets have been annotated **(0 = Negative, 4 = Positive)** and they can be used to detect sentiment.\n",
        "\n",
        "*The **training data isn't perfectly categorised** as it has been created by tagging the text according to the emoji present. So, any model built using this dataset **may have lower than expected accuracy**, since the dataset isn't perfectly categorised.*\n",
        "\n",
        "It contains the following 6 fields:\n",
        "\n",
        "- **sentiment**: the polarity of the tweet (0 = negative, 4 = positive)\n",
        "- ids The id of the tweet (2087)\n",
        "- date the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
        "- flag: The query (lyx). If there is no query, then this value is NO_QUERY.\n",
        "- user: the user that tweeted (robotickilldozr)\n",
        "- **text**: the text of the tweet (Lyx is cool)\n",
        "\n",
        "We require only the **sentiment** and **text** fields, so we discard the rest.\\\n",
        "Furthermore, we're **changing the sentiment field** so that it has new values to reflect the sentiment. (**0 = Negative, 1 = Positive**)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7efff2a-ae3c-41cb-ba1f-a25de3f0a756",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7efff2a-ae3c-41cb-ba1f-a25de3f0a756",
        "outputId": "c406ba49-563c-4d62-f9dd-556d37dda7af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd drive/MyDrive\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#config\n",
        "data_dir = '/content/drive/MyDrive/NLP'"
      ],
      "metadata": {
        "id": "1HywYsCPXTQm"
      },
      "id": "1HywYsCPXTQm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52792ff6-38ea-48be-9133-f2bef99972d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 603
        },
        "id": "52792ff6-38ea-48be-9133-f2bef99972d2",
        "outputId": "294f5567-f2ca-4293-a2ce-386cb4c67681"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-10a340c3be2e>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataset['sentiment'] = dataset['sentiment'].replace(4,1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Importing the dataset\n",
        "DATASET_COLUMNS  = [\"sentiment\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
        "DATASET_ENCODING = \"ISO-8859-1\"\n",
        "dataset = pd.read_csv(f'{data_dir}/training.1600000.processed.noemoticon.csv',\n",
        "                      encoding=DATASET_ENCODING , names=DATASET_COLUMNS)\n",
        "\n",
        "# Removing the unnecessary columns.\n",
        "dataset = dataset[['sentiment','text']]\n",
        "# Replacing the values to ease understanding.\n",
        "dataset['sentiment'] = dataset['sentiment'].replace(4,1)\n",
        "\n",
        "# Plotting the distribution for dataset.\n",
        "ax = dataset.groupby('sentiment').count().plot(kind='bar', title='Distribution of data', legend=False)\n",
        "ax.set_xticklabels(['Negative','Positive'], rotation=0)\n",
        "\n",
        "# Storing data in lists.\n",
        "text, sentiment = list(dataset['text']), list(dataset['sentiment'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65f2673f-987d-41c8-80af-acd7e3eb1cf8",
      "metadata": {
        "id": "65f2673f-987d-41c8-80af-acd7e3eb1cf8"
      },
      "source": [
        "## Preprocess Text\n",
        "Text Preprocessing is traditionally an important step for Natural Language Processing (NLP) tasks. It transforms text into a more digestible form so that machine learning algorithms can perform better.\n",
        "\n",
        "The **Preprocessing steps** taken are:\n",
        "\n",
        "- Lower Casing: Each text is converted to lowercase.\n",
        "- Replacing URLs: Links starting with \"http\" or \"https\" or \"www\" are replaced by \"URL\".\n",
        "- Replacing Emojis: Replace emojis by using a pre-defined dictionary containing emojis along with their meaning. (eg: \":)\" to \"EMOJIsmile\")\n",
        "- Replacing Usernames: Replace @Usernames with word \"USER\". (eg: \"@Kaggle\" to \"USER\")\n",
        "- Removing Non-Alphabets: Replacing characters except Digits and Alphabets with a space.\n",
        "- Removing Consecutive letters: 3 or more consecutive letters are replaced by 2 letters. (eg: \"Heyyyy\" to \"Heyy\")\n",
        "- Removing Short Words: Words with length less than 2 are removed.\n",
        "- Removing Stopwords: Stopwords are the English words which does not add much meaning to a sentence. They can safely be ignored without sacrificing the - meaning of the sentence. (eg: \"the\", \"he\", \"have\")\n",
        "- Lemmatizing: Lemmatization is the process of converting a word to its base form. (e.g: “Great” to “Good”)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38ab4045-e8b1-4416-8ddc-fdd685ed0093",
      "metadata": {
        "id": "38ab4045-e8b1-4416-8ddc-fdd685ed0093"
      },
      "outputs": [],
      "source": [
        "# Defining dictionary containing all emojis with their meanings.\n",
        "emojis = {':)': 'smile', ':-)': 'smile', ';d': 'wink', ':-E': 'vampire', ':(': 'sad',\n",
        "          ':-(': 'sad', ':-<': 'sad', ':P': 'raspberry', ':O': 'surprised',\n",
        "          ':-@': 'shocked', ':@': 'shocked',':-$': 'confused', ':\\\\': 'annoyed',\n",
        "          ':#': 'mute', ':X': 'mute', ':^)': 'smile', ':-&': 'confused', '$_$': 'greedy',\n",
        "          '@@': 'eyeroll', ':-!': 'confused', ':-D': 'smile', ':-0': 'yell', 'O.o': 'confused',\n",
        "          '<(-_-)>': 'robot', 'd[-_-]b': 'dj', \":'-)\": 'sadsmile', ';)': 'wink',\n",
        "          ';-)': 'wink', 'O:-)': 'angel','O*-)': 'angel','(:-D': 'gossip', '=^.^=': 'cat'}\n",
        "\n",
        "## Defining set containing all stopwords in english.\n",
        "stopwordlist = ['a', 'about', 'above', 'after', 'again', 'ain', 'all', 'am', 'an',\n",
        "             'and','any','are', 'as', 'at', 'be', 'because', 'been', 'before',\n",
        "             'being', 'below', 'between','both', 'by', 'can', 'd', 'did', 'do',\n",
        "             'does', 'doing', 'down', 'during', 'each','few', 'for', 'from',\n",
        "             'further', 'had', 'has', 'have', 'having', 'he', 'her', 'here',\n",
        "             'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in',\n",
        "             'into','is', 'it', 'its', 'itself', 'just', 'll', 'm', 'ma',\n",
        "             'me', 'more', 'most','my', 'myself', 'now', 'o', 'of', 'on', 'once',\n",
        "             'only', 'or', 'other', 'our', 'ours','ourselves', 'out', 'own', 're',\n",
        "             's', 'same', 'she', \"shes\", 'should', \"shouldve\",'so', 'some', 'such',\n",
        "             't', 'than', 'that', \"thatll\", 'the', 'their', 'theirs', 'them',\n",
        "             'themselves', 'then', 'there', 'these', 'they', 'this', 'those',\n",
        "             'through', 'to', 'too','under', 'until', 'up', 've', 'very', 'was',\n",
        "             'we', 'were', 'what', 'when', 'where','which','while', 'who', 'whom',\n",
        "             'why', 'will', 'with', 'won', 'y', 'you', \"youd\",\"youll\", \"youre\",\n",
        "             \"youve\", 'your', 'yours', 'yourself', 'yourselves']\n",
        "def preprocess(textdata):\n",
        "    processedText = []\n",
        "\n",
        "    # Create Lemmatizer and Stemmer.\n",
        "    wordLemm = WordNetLemmatizer()\n",
        "\n",
        "    # Defining regex patterns.\n",
        "    urlPattern        = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
        "    userPattern       = '@[^\\s]+'\n",
        "    alphaPattern      = \"[^a-zA-Z0-9]\"\n",
        "    sequencePattern   = r\"(.)\\1\\1+\"\n",
        "    seqReplacePattern = r\"\\1\\1\"\n",
        "\n",
        "    for tweet in textdata:\n",
        "        tweet = tweet.lower()\n",
        "\n",
        "        # Replace all URls with 'URL'\n",
        "        tweet = re.sub(urlPattern,' URL',tweet)\n",
        "        # Replace all emojis.\n",
        "        for emoji in emojis.keys():\n",
        "            tweet = tweet.replace(emoji, \"EMOJI\" + emojis[emoji])\n",
        "        # Replace @USERNAME to 'USER'.\n",
        "        tweet = re.sub(userPattern,' USER', tweet)\n",
        "        # Replace all non alphabets.\n",
        "        tweet = re.sub(alphaPattern, \" \", tweet)\n",
        "        # Replace 3 or more consecutive letters by 2 letter.\n",
        "        tweet = re.sub(sequencePattern, seqReplacePattern, tweet)\n",
        "\n",
        "        tweetwords = ''\n",
        "        for word in tweet.split():\n",
        "            # Checking if the word is a stopword.\n",
        "            #if word not in stopwordlist:\n",
        "            if len(word)>1:\n",
        "                # Lemmatizing the word.\n",
        "                word = wordLemm.lemmatize(word)\n",
        "                tweetwords += (word+' ')\n",
        "\n",
        "        processedText.append(tweetwords)\n",
        "\n",
        "    return processedText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f264ad7d-1d56-4164-8709-e153742730e4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f264ad7d-1d56-4164-8709-e153742730e4",
        "outputId": "240dc5ea-a743-45a9-fadd-f8cb60ff7547"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Preprocessing complete.\n",
            "Time Taken: 122 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "t = time.time()\n",
        "processedtext = preprocess(text)\n",
        "print(f'Text Preprocessing complete.')\n",
        "print(f'Time Taken: {round(time.time()-t)} seconds')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <mark> BERT 작성중 <mark>"
      ],
      "metadata": {
        "id": "2Q7Qqdpklm6j"
      },
      "id": "2Q7Qqdpklm6j"
    },
    {
      "cell_type": "code",
      "source": [
        "# Bert 사용에 필요한 모듈 불러오기\n",
        "import torch\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, Adafactor, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import random\n",
        "import datetime"
      ],
      "metadata": {
        "id": "ae8qC-tvlrxA"
      },
      "id": "ae8qC-tvlrxA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT gpu 사용하기\n",
        "import os\n",
        "\n",
        "n_devices = torch.cuda.device_count()\n",
        "print(n_devices)\n",
        "\n",
        "for i in range(n_devices):\n",
        "    print(torch.cuda.get_device_name(i))"
      ],
      "metadata": {
        "id": "0kMpJVmhlyzR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e059f919-822c-412e-9ddf-ea125d30e371"
      },
      "id": "0kMpJVmhlyzR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT에 맞는 Tag 달아주기\n",
        "bert_text = []\n",
        "train_data = processedtext[:100000]\n",
        "\n",
        "for i in train_data:\n",
        "  bert = [\"[CLS] \" + str(i) + \" [SEP]\"]\n",
        "  bert_text.append(bert)\n",
        "\n",
        "bert_text[:5]"
      ],
      "metadata": {
        "id": "di9i3rlkl46R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a224e4be-d2dc-467a-c705-f5e2249f3d5e"
      },
      "id": "di9i3rlkl46R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['[CLS] USER URL aww that bummer you shoulda got david carr of third day to do it EMOJIwink  [SEP]'],\n",
              " ['[CLS] is upset that he can update his facebook by texting it and might cry a result school today also blah  [SEP]'],\n",
              " ['[CLS] USER dived many time for the ball managed to save 50 the rest go out of bound  [SEP]'],\n",
              " ['[CLS] my whole body feel itchy and like it on fire  [SEP]'],\n",
              " ['[CLS] USER no it not behaving at all mad why am here because can see you all over there  [SEP]']]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = processedtext[100000:180000]\n",
        "test_text = []\n",
        "\n",
        "for i in test_data:\n",
        "  bert = [\"[CLS] \" + str(i) + \" [SEP]\"]\n",
        "  test_text.append(bert)\n",
        "\n",
        "test_text[:5]"
      ],
      "metadata": {
        "id": "9W1YQxGZnbv2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "951823ca-344b-4e0f-b032-b94e31041bdd"
      },
      "id": "9W1YQxGZnbv2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['[CLS] omg just moisturised and my leg are burning me it really hurt go away  [SEP]'],\n",
              " ['[CLS] USER yeah just good deadpool wa waay wrong  [SEP]'],\n",
              " ['[CLS] feel bad for danny gokey  [SEP]'],\n",
              " ['[CLS] how much blood do they need from they took even more today  [SEP]'],\n",
              " ['[CLS] USER my reply is no  [SEP]']]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num = 250000\n",
        "train_num = int(num*0.7)\n",
        "test_num = int(num*0.3)\n",
        "\n",
        "train_neg = int(train_num/2)\n",
        "test_neg = int(test_num/2)\n",
        "\n",
        "sentiment_train = sentiment[:train_neg]\n",
        "sentiment_train.extend(sentiment[800000:800000+train_neg])\n",
        "\n",
        "sentiment_test = sentiment[train_neg:train_neg+test_neg]\n",
        "sentiment_test.extend(sentiment[800000+train_neg:800000+train_neg+test_neg])"
      ],
      "metadata": {
        "id": "hqoX1bkYEg4d"
      },
      "id": "hqoX1bkYEg4d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del(text)\n",
        "# tokenizing 오래걸림 주의\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
        "tokenized_data = []\n",
        "for i in bert_text:\n",
        "  for j in i:\n",
        "    tokens = tokenizer.tokenize(j)\n",
        "    tokenized_data.append(tokens)\n",
        "print(tokenized_data[0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294,
          "referenced_widgets": [
            "528261c4c39f4d44ab46f784a914574c",
            "840b7ebb5fed494ea917fd9f9283a187",
            "351c11a2a1484d45b7a56284b69b0631",
            "24105b2a1347429ca18833d67b78cbc8",
            "e8338060cd624ab3a16ecb412f237760",
            "488a8fbdd9b94cfdba1323712744eb23",
            "d868cc8b543f4a78ae6a1519e6ecfabf",
            "f3b0d2248a704fb3983bd26636839227",
            "b56d41cb236b426791713b2f28462a9c",
            "93a68eb293cf4581b2785f7a28d9a0c0",
            "bf5108769244495daa4d5c99c40afc1e",
            "e8b52ecd29fc4dca97cf3182ee15175d",
            "e4a43f2d33e44da6887819dea6f51484",
            "3ebcd04cb9ba49f4bc8d82a07e966ee2",
            "c3c444635c4846bbb31c14a6e4f355ad",
            "0c15f018e8c24dcab945e09e729b96fc",
            "01d459281fad4a868534321cf7f9d339",
            "f649300ed45b48c6be5d8dd3fcd79be2",
            "1ae446c5c8ea4b7d9647eac7e92ed1c2",
            "fa5ed9d8a7b543cf90e387a34e766225",
            "39df54c9df0e4b69a2aaa3fbf95dd8ad",
            "4aa8865ba4f043429ef322ccd0073571",
            "f87661bce9514bafbbdeedb7ac4323d5",
            "b1ea5dcd79c242d2a14d32479405c20f",
            "3886ff12aebe48b98d56f0cae2ab349e",
            "f134b1f6e6a841609560e788c344812f",
            "4687ce12cd4845a39ce3801c26848a4f",
            "30f5526ad6d44460b5fe6f81e64129a8",
            "40e0326f40c3461f8d02219a4683a5bd",
            "b4d607b795b348c287deee1737772128",
            "0c3beb9b76ec45c2a649ac1beebfcf28",
            "df0c8e8c9f8343e2b6951cd6e09e24de",
            "9c6d57bcf97f4ead9878fe9aa5398462",
            "6a424265667546bc9600df7f1067aab7",
            "c3c8b5197ae74a10a6f7c67c3576b37f",
            "f8bbc301d5974879835d4d058d481502",
            "d38c6ac71453418889a0bfd7cf0fe8a9",
            "5a95c7b98f67474bb12331edb1ecabe9",
            "bd24232fa5f84ffcb96b52a26ff56e78",
            "0420692fd4ec4661b445cea1f42e2695",
            "10df7a3b1ba14d0a8c8de2055d0f16d1",
            "36e8ec5a160244a98fe84a2402ec4753",
            "aab4ed46c1c942ebb82c77b3f6957dbf",
            "adf730615ce445ea83ae535156f5bdd8"
          ]
        },
        "id": "3Sbxf09Unm1M",
        "outputId": "e764058d-1795-456d-988c-2834d23def0b"
      },
      "id": "3Sbxf09Unm1M",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "528261c4c39f4d44ab46f784a914574c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8b52ecd29fc4dca97cf3182ee15175d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f87661bce9514bafbbdeedb7ac4323d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a424265667546bc9600df7f1067aab7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['[CLS]', 'US', '##ER', 'URL', 'aw', '##w', 'that', 'bu', '##mmer', 'you', 'should', '##a', 'got', 'da', '##vid', 'car', '##r', 'of', 'third', 'day', 'to', 'do', 'it', 'EM', '##O', '##J', '##I', '##win', '##k', '[SEP]'], ['[CLS]', 'is', 'upset', 'that', 'he', 'can', 'update', 'his', 'face', '##book', 'by', 'text', '##ing', 'it', 'and', 'might', 'c', '##ry', 'a', 'result', 'school', 'today', 'also', 'bl', '##ah', '[SEP]'], ['[CLS]', 'US', '##ER', 'div', '##ed', 'many', 'time', 'for', 'the', 'ball', 'managed', 'to', 'save', '50', 'the', 'rest', 'go', 'out', 'of', 'bound', '[SEP]'], ['[CLS]', 'my', 'whole', 'body', 'feel', 'it', '##chy', 'and', 'like', 'it', 'on', 'fire', '[SEP]'], ['[CLS]', 'US', '##ER', 'no', 'it', 'not', 'be', '##hav', '##ing', 'at', 'all', 'ma', '##d', 'why', 'am', 'here', 'because', 'can', 'see', 'you', 'all', 'over', 'there', '[SEP]'], ['[CLS]', 'US', '##ER', 'not', 'the', 'whole', 'crew', '[SEP]'], ['[CLS]', 'need', 'hu', '##g', '[SEP]'], ['[CLS]', 'US', '##ER', 'he', '##y', 'long', 'time', 'no', 'see', 'ye', '##s', 'rain', 'bit', 'only', 'bit', 'lo', '##l', 'fine', 'thanks', 'how', 'you', '[SEP]'], ['[CLS]', 'US', '##ER', 'no', '##pe', 'they', 'didn', 'have', 'it', '[SEP]'], ['[CLS]', 'US', '##ER', 'que', 'me', 'mu', '##era', '[SEP]']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_test_data = []\n",
        "for i in test_text:\n",
        "  for j in i:\n",
        "    tokens = tokenizer.tokenize(j)\n",
        "    tokenized_test_data.append(tokens)"
      ],
      "metadata": {
        "id": "PBfOyLDbnuLm"
      },
      "id": "PBfOyLDbnuLm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# padding\n",
        "input_ids = []\n",
        "for i in tokenized_data:\n",
        "  ids = tokenizer.convert_tokens_to_ids(i)\n",
        "  input_ids.append(ids)\n",
        "\n",
        "input_ids_test = []\n",
        "for i in tokenized_test_data:\n",
        "  ids = tokenizer.convert_tokens_to_ids(i)\n",
        "  input_ids_test.append(ids)\n",
        "\n",
        "print(input_ids[0])\n",
        "print(input_ids_test[0])\n",
        "\n",
        "max_len = 128\n",
        "input_ids = pad_sequences(input_ids, maxlen=max_len, dtype='long', truncating='post', padding='post')\n",
        "\n",
        "input_ids_test = pad_sequences(input_ids_test, maxlen=max_len, dtype='long', truncating='post', padding='post')\n",
        "\n",
        "# masking\n",
        "attention_masks = []\n",
        "\n",
        "for ids in input_ids:\n",
        "  ids_mask = []\n",
        "  for id in ids:\n",
        "      masked = float(id>0)\n",
        "      ids_mask.append(masked)\n",
        "  attention_masks.append(ids_mask)\n",
        "\n",
        "attention_masks_test = []\n",
        "\n",
        "for ids in input_ids_test:\n",
        "  ids_mask = []\n",
        "  for id in ids:\n",
        "      masked = float(id>0)\n",
        "      ids_mask.append(masked)\n",
        "  attention_masks_test.append(ids_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXrozam8n2UD",
        "outputId": "43792bc6-16b0-4897-8040-48fb6b3f6332"
      },
      "id": "GXrozam8n2UD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 10808, 24093, 31191, 56237, 10874, 10189, 11499, 26944, 13028, 14819, 10113, 19556, 10143, 32194, 13000, 10129, 10108, 12628, 11940, 10114, 10149, 10271, 20569, 11403, 15417, 11281, 24748, 10174, 102]\n",
            "[101, 10209, 10240, 12820, 17083, 40388, 16219, 10111, 15127, 33810, 10301, 78514, 10911, 10271, 30181, 52824, 10123, 11783, 14942, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train, validation 분리\n",
        "\n",
        "train_label = np.array(sentiment[:100000])\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    input_ids, train_label, random_state=42, test_size=0.2)\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks,\n",
        "                                                       input_ids,\n",
        "                                                       random_state=42,\n",
        "                                                       test_size=0.2)"
      ],
      "metadata": {
        "id": "nFo13g_3oMgP"
      },
      "id": "nFo13g_3oMgP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape,  X_val.shape, y_train.shape, y_val.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_w1QsH2KqnG-",
        "outputId": "e94383f1-1db5-44a7-f376-56ab1aac8da7"
      },
      "id": "_w1QsH2KqnG-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((80000, 128), (20000, 128), (80000,), (20000,))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tuning과 Tensor로 사용할 데이터를 분리\n",
        "X_train_tune = X_train\n",
        "y_train_tune = y_train\n",
        "X_val_tune = X_val\n",
        "y_val_tune = y_val\n",
        "\n",
        "X_test_tensor = input_ids_test\n",
        "y_test_tensor = np.array(sentiment[100000:180000])\n",
        "test_masks = attention_masks_test"
      ],
      "metadata": {
        "id": "tOjAdDItquCM"
      },
      "id": "tOjAdDItquCM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch로 변환\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train)\n",
        "y_train_tensor = torch.tensor(y_train)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "X_val_tensor = torch.tensor(X_val)\n",
        "y_val_tensor = torch.tensor(y_val)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "\n",
        "X_test_tensor = torch.tensor(X_test_tensor)\n",
        "y_test_tensor = torch.tensor(y_test_tensor)\n",
        "test_masks = torch.tensor(attention_masks_test)"
      ],
      "metadata": {
        "id": "3TR1ZpTVrCHl"
      },
      "id": "3TR1ZpTVrCHl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch size 는 8의 배수인 것이 좋\n",
        "batch_size = 32\n",
        "\n",
        "train = TensorDataset(X_train_tensor, train_masks, y_train_tensor)\n",
        "train_sampler = RandomSampler(train)\n",
        "\n",
        "val = TensorDataset(X_val_tensor, validation_masks, y_val_tensor)\n",
        "val_sampler = SequentialSampler(val)\n",
        "\n",
        "\n",
        "test = TensorDataset(X_test_tensor, test_masks, y_test_tensor)\n",
        "test_sampler = RandomSampler(test)\n",
        "\n",
        "train_dataloader = DataLoader(train, sampler=train_sampler, batch_size=batch_size)\n",
        "val_dataloader = DataLoader(val, sampler=val_sampler, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test, sampler=test_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "d9wRpj4-rLW3"
      },
      "id": "d9wRpj4-rLW3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 사용 가능 여부\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhl82TVirSk5",
        "outputId": "cda6bd84-e2a7-4a1f-ab00-ded70999de31"
      },
      "id": "qhl82TVirSk5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU available, using the CPU instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT모델은 Fine-Tuning을 통해 원하는 목적에 맞게 최적화 시킬 수도 있다.\n",
        "# 이번 단계에서는 모델의 최종 학습 전, 모델을 Fine-Tuning하여 성능을 올리고자 한다.\n",
        "# 일단 BERT 모델을 초기화한다. Transformers의 BertForSequenceClassification 모듈을 활용한다.\n",
        "#  타깃은 0과 1로 이루어져 있기 때문에, 라벨의 수는 2가 될 것이다.\n",
        "# 사용할 BERT모듈의 이름은 \"bert-case-multilingual-cased\"라는 것으로 영어 이외의 언어 텍스트 데이터를 처리하는데 유용하다.\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1s-ef1WRrU-R",
        "outputId": "4eadd851-7b6f-4f9b-d4ab-5501d2e613c7"
      },
      "id": "1s-ef1WRrU-R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 파라미터만 Fine-Tuning을 진행할 수 있도록 requires_grad를 False로 설정한다.\n",
        "for param in model.base_model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "AIKYHXqprsvW"
      },
      "id": "AIKYHXqprsvW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_docs, val_docs, train_labels, val_labels = train_test_split(\n",
        "    train_data,\n",
        "    sentiment[:100000],\n",
        "    test_size=.2\n",
        ")"
      ],
      "metadata": {
        "id": "jSV0hyIIxyoN"
      },
      "id": "jSV0hyIIxyoN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "model_name = \"bert-base-multilingual-cased\"\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
        "\n",
        "train_encodings = tokenizer(train_docs, truncation=True, padding='max_length', max_length=max_len)\n",
        "val_encodings = tokenizer(val_docs, truncation=True, padding='max_length', max_length=max_len)"
      ],
      "metadata": {
        "id": "3FlfqWXHx6U3"
      },
      "id": "3FlfqWXHx6U3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Cord19Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = Cord19Dataset(train_encodings, train_labels)\n",
        "val_dataset = Cord19Dataset(val_encodings, val_labels)"
      ],
      "metadata": {
        "id": "WEr54ufGzS4c"
      },
      "id": "WEr54ufGzS4c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPUKoTXWzjmo",
        "outputId": "f6ac1acb-ae8f-4914-b784-676fcd0f54a8"
      },
      "id": "WPUKoTXWzjmo",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m823.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.28.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "wUw58_xW1uDV",
        "outputId": "fb05e2c6-802c-4932-d70b-700ff261ef34"
      },
      "id": "wUw58_xW1uDV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.39.0-py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.2\n",
            "    Uninstalling transformers-4.38.2:\n",
            "      Successfully uninstalled transformers-4.38.2\n",
            "Successfully installed transformers-4.39.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "transformers"
                ]
              },
              "id": "824f38107cb245c6850f92a99b100b57"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "# 오래걸림 주\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    evaluation_strategy=\"epoch\",     # Evaluation is done at the end of each epoch.\n",
        "    num_train_epochs=2,              # total number of training epochs\n",
        "    per_device_train_batch_size=32,  # batch size per device during training\n",
        "    per_device_eval_batch_size=32,   # batch size for evaluation\n",
        "    warmup_steps=0,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0,               # strength of weight decay\n",
        "    save_total_limit=1,              # limit the total amount of checkpoints. Deletes the older checkpoints.\n",
        ")\n",
        "\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset             # evaluation dataset\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "zeEPxxD4zaT2",
        "outputId": "00cc318c-3662-4fbb-99f8-6da187f599c2"
      },
      "id": "zeEPxxD4zaT2",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5000' max='5000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5000/5000 24:51, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.003600</td>\n",
              "      <td>0.000463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.002100</td>\n",
              "      <td>0.000212</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5000, training_loss=0.014590991592407227, metrics={'train_runtime': 1493.1207, 'train_samples_per_second': 107.158, 'train_steps_per_second': 3.349, 'total_flos': 1.05244422144e+16, 'train_loss': 0.014590991592407227, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 옵티마이저 설정\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 1e-5, # 학습률\n",
        "                  eps = 1e-8 # 0으로 나누는 것을 방지하기 위한 epsilon 값,\n",
        "                )\n",
        "# 에폭수\n",
        "epochs = 3\n",
        "\n",
        "# 총 훈련 스텝\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Learning rate decay를 위한 스케줄러\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4odKh8W3I1A",
        "outputId": "1d6ad2c0-2771-4587-bf99-bc493d440dc3"
      },
      "id": "U4odKh8W3I1A",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:429: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 정확도 계산 함수\n",
        "def accuracy_measure(y_pred, y):\n",
        "    pred_flattened = np.argmax(y_pred, axis=1).flatten()\n",
        "    y_flattened = y.flatten()\n",
        "    return np.sum(pred_flattened == y_flattened) / len(y_flattened)\n",
        "\n",
        "# 시간 표시 함수\n",
        "def time_elapsed(elapsed):\n",
        "    # 반올림\n",
        "    elapsed = int(round((elapsed)))\n",
        "    # hh:mm:ss으로 형태 변경\n",
        "    return str(datetime.timedelta(seconds=elapsed))\n"
      ],
      "metadata": {
        "id": "PEv7bZ3ezqQw"
      },
      "id": "PEv7bZ3ezqQw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 재현을 위해 랜덤시드 고정\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# 그래디언트 초기화\n",
        "model.zero_grad()"
      ],
      "metadata": {
        "id": "FedmHl2jwbmV"
      },
      "id": "FedmHl2jwbmV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 본격적인 학습\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "\n",
        "    # 현재 훈련 조건 표시\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # 시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 로스 초기화\n",
        "    total_loss = 0\n",
        "\n",
        "    # 훈련모드로 변경\n",
        "    model.train()\n",
        "\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # 경과 정보 표시\n",
        "        if step % 500 == 0 and not step == 0:\n",
        "          elapsed = time_elapsed(time.time() - t0)\n",
        "          print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Forward 수행\n",
        "        outputs = model(b_input_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=b_input_mask,\n",
        "                            labels=b_labels)\n",
        "\n",
        "        # 로스 구함\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # 총 로스 계산\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Backward 수행으로 그래디언트 계산\n",
        "        loss.backward()\n",
        "\n",
        "        # 그래디언트 클리핑\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 스케줄러로 학습률 감소\n",
        "        scheduler.step()\n",
        "\n",
        "        # 그래디언트 초기화\n",
        "        model.zero_grad()\n",
        "\n",
        "    # 평균 로스 계산\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(time_elapsed(time.time() - t0)))\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    #시작 시간 설정\n",
        "    t0 = time.time()\n",
        "\n",
        "    # 평가모드로 변경\n",
        "    model.eval()\n",
        "\n",
        "    # 변수 초기화\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "    for batch in val_dataloader:\n",
        "        # 배치를 GPU에 넣음\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # 배치에서 데이터 추출\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # 그래디언트 계산 안함\n",
        "        with torch.no_grad():\n",
        "          # Forward 수행\n",
        "          outputs = model(b_input_ids,\n",
        "                                token_type_ids=None,\n",
        "                                attention_mask=b_input_mask)\n",
        "\n",
        "          # 로스 구함\n",
        "          logits = outputs[0]\n",
        "\n",
        "          # CPU로 데이터 이동\n",
        "          logits = logits.detach().cpu().numpy()\n",
        "          label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "          # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "          tmp_eval_accuracy = accuracy_measure(logits, label_ids)\n",
        "          eval_accuracy += tmp_eval_accuracy\n",
        "          nb_eval_steps += 1\n",
        "\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(time_elapsed(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fapi2MILwdS0",
        "outputId": "dc4ee9b5-824f-4833-d193-0ddcc53a0a5b"
      },
      "id": "fapi2MILwdS0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch   500  of  2,500.    Elapsed: 0:01:57.\n",
            "  Batch 1,000  of  2,500.    Elapsed: 0:03:53.\n",
            "  Batch 1,500  of  2,500.    Elapsed: 0:05:48.\n",
            "  Batch 2,000  of  2,500.    Elapsed: 0:07:44.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:09:38\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "  Validation took: 0:02:20\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch   500  of  2,500.    Elapsed: 0:01:55.\n",
            "  Batch 1,000  of  2,500.    Elapsed: 0:03:50.\n",
            "  Batch 1,500  of  2,500.    Elapsed: 0:05:45.\n",
            "  Batch 2,000  of  2,500.    Elapsed: 0:07:40.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:09:35\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "  Validation took: 0:02:21\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch   500  of  2,500.    Elapsed: 0:01:55.\n",
            "  Batch 1,000  of  2,500.    Elapsed: 0:03:50.\n",
            "  Batch 1,500  of  2,500.    Elapsed: 0:05:45.\n",
            "  Batch 2,000  of  2,500.    Elapsed: 0:07:41.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:09:36\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 1.00\n",
            "  Validation took: 0:02:20\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#시작 시간 설정\n",
        "t0 = time.time()\n",
        "\n",
        "# 평가모드로 변경\n",
        "model.eval()\n",
        "\n",
        "# 변수 초기화\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "    # 경과 정보 표시\n",
        "    if step % 100 == 0 and not step == 0:\n",
        "        elapsed = time_elapsed(time.time() - t0)\n",
        "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
        "\n",
        "    # 배치를 GPU에 넣음\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    # 배치에서 데이터 추출\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    # 그래디언트 계산 안함\n",
        "    with torch.no_grad():\n",
        "        # Forward 수행\n",
        "        outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "    # 로스 구함\n",
        "    logits = outputs[0]\n",
        "\n",
        "    # CPU로 데이터 이동\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "    tmp_eval_accuracy = accuracy_measure(logits, label_ids)\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "print(\"\")\n",
        "print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "print(\"Test took: {:}\".format(time_elapsed(time.time() - t0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "AJ-nU7RswgAR",
        "outputId": "cbaf03ef-e5d4-45b1-afe8-3a313363a970"
      },
      "id": "AJ-nU7RswgAR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-3d416ba55f35>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Forward 수행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         outputs = model(b_input_ids,\n\u001b[0m\u001b[1;32m     28\u001b[0m                         \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                         attention_mask=b_input_mask)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1562\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1564\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1565\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         )\n\u001b[0;32m-> 1013\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m   1014\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    605\u001b[0m                 )\n\u001b[1;32m    606\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    608\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    540\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# file = open('Sentiment-BNB-youtube.pickle-trump','wb')\n",
        "# pickle.dump(model, file)\n",
        "# file.close()\n",
        "\n",
        "#odel.save(\"topic_model\")\n",
        "model.save_pretrained(\"bert_twitter\")\n",
        "\n",
        "# from bertopic import BERTopic\n",
        "# model2 = BERTopic.load(\"topic_model\")\n",
        "# model2.visualize_barchart()"
      ],
      "metadata": {
        "id": "OuS_fsHr8qpJ"
      },
      "id": "OuS_fsHr8qpJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<hr>YouTube Test Code<hr>\n",
        "\n"
      ],
      "metadata": {
        "id": "mUN22aGNbAFu"
      },
      "id": "mUN22aGNbAFu"
    },
    {
      "cell_type": "code",
      "source": [
        "comments = pd.read_csv(f'{data_dir}/youtube_ai_comments_20240419_17_57.csv',\n",
        "                      encoding=DATASET_ENCODING)\n",
        "comments_colums = [\"id\", \"unnamed: 0\", \"author\", \"published_at\", \"updated_at\", \"like_count\", \"text\"]\n",
        "text_comments = list(comments['text'])"
      ],
      "metadata": {
        "id": "pZIP5GLqZdjp"
      },
      "id": "pZIP5GLqZdjp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForMaskedLM\n",
        "model = BertForMaskedLM.from_pretrained(f'bert_twitter')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDJPNZPJa-uN",
        "outputId": "d3facefd-1638-499e-a2f3-eea12957f0ff"
      },
      "id": "lDJPNZPJa-uN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert_twitter and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFBertModel\n",
        "model = TFBertModel.from_pretrained(f'bert_twitter')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XO_FyaW9eLtW",
        "outputId": "616deb99-d275-4a87-cbf3-b020c6dc8c73"
      },
      "id": "XO_FyaW9eLtW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['classifier.bias', 'classifier.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_text = []\n",
        "for i in text_comments:\n",
        "  bert = [\"[CLS] \" + str(i) + \" [SEP]\"]\n",
        "  bert_text.append(bert)\n",
        "bert_text[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0jHK7tgemMp",
        "outputId": "771019a5-da60-4019-e8ba-6cafc2b2043d"
      },
      "id": "g0jHK7tgemMp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['[CLS] More productive? <br>Shouldn&#39;t we just much rather learn how to chill and be happy with less? [SEP]'],\n",
              " ['[CLS] This is just simple, the rich will get richer through Ai , while the poor remain poorð\\x9f\\x98¢ [SEP]'],\n",
              " ['[CLS] Eventually artificial intelligence will take over all human jobs. UBI Will have to be introduced. [SEP]'],\n",
              " ['[CLS] The down side of AI is that big cities like Berlin or London, which have the highest concentration of software and office workers will see a huge rise in permanent unemployment. I think these cities will soon face the Detroit syndrome. [SEP]'],\n",
              " ['[CLS] â\\x9c¨ <b><i>&quot;A.I. isn&#39;t about making machines more human like, but to make humans more machine like.&quot;</i></b> â\\x9c¨ [SEP]']]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case=False)\n",
        "tokenized_data = []\n",
        "for i in bert_text:\n",
        "  for j in i:\n",
        "    tokens = tokenizer.tokenize(j)\n",
        "    tokenized_data.append(tokens)\n",
        "print(tokenized_data[0:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2OsoxYTfQx-",
        "outputId": "243d17d1-6505-449d-e3e9-194f6aab8886"
      },
      "id": "M2OsoxYTfQx-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['[CLS]', 'More', 'product', '##ive', '?', '<', 'br', '>', 'Should', '##n', '&', '#', '39', ';', 't', 'we', 'just', 'much', 'rather', 'learn', 'how', 'to', 'chi', '##ll', 'and', 'be', 'happy', 'with', 'less', '?', '[SEP]'], ['[CLS]', 'This', 'is', 'just', 'simple', ',', 'the', 'rich', 'will', 'get', 'riche', '##r', 'through', 'Ai', ',', 'while', 'the', 'poor', 'remain', 'poor', '##ð', '##¢', '[SEP]'], ['[CLS]', 'Eventually', 'artificial', 'intelligence', 'will', 'take', 'over', 'all', 'human', 'jobs', '.', 'UB', '##I', 'Will', 'have', 'to', 'be', 'introduced', '.', '[SEP]'], ['[CLS]', 'The', 'down', 'side', 'of', 'AI', 'is', 'that', 'big', 'cities', 'like', 'Berlin', 'or', 'London', ',', 'which', 'have', 'the', 'highest', 'concentration', 'of', 'software', 'and', 'office', 'workers', 'will', 'see', 'a', 'huge', 'rise', 'in', 'permanent', 'une', '##mployment', '.', 'I', 'think', 'these', 'cities', 'will', 'soon', 'face', 'the', 'Detroit', 'syndrome', '.', '[SEP]'], ['[CLS]', 'â', '##¨', '<', 'b', '>', '<', 'i', '>', '&', 'quo', '##t', ';', 'A', '.', 'I', '.', 'isn', '&', '#', '39', ';', 't', 'about', 'making', 'machines', 'more', 'human', 'like', ',', 'but', 'to', 'make', 'humans', 'more', 'machine', 'like', '.', '&', 'quo', '##t', ';', '<', '/', 'i', '>', '<', '/', 'b', '>', 'â', '##¨', '[SEP]'], ['[CLS]', 'What', 'a', 'tou', '##gh', 'line', 'of', 'question', '##ing', 'big', 'business', 'owners', 'concerns', '.', '.', '.', 'Their', 'concern', 'is', 'turning', 'in', 'more', 'profit', 'and', 'the', 'thousands', 'they', 'could', 'sac', '##k', 'as', 'a', 'result', '.', 'Nothing', 'to', 'be', 'wo', '##rri', '##ed', 'about', 'for', 'them', ',', 'I', 'think', 'it', '&', '#', '39', ';', 's', 'kind', 'of', 'mind', 'ben', '##ding', 'that', 'we', '&', '#', '39', ';', 've', 'let', 'ai', 'go', 'online', 'and', 'create', 'it', '&', '#', '39', ';', 's', 's', 'own', 'code', 'this', 'was', 'ment', 'be', 'the', 'very', 'basic', 'premi', '##se', 'of', 'safe', '##ly', 'developing', 'AI', '.', '[SEP]'], ['[CLS]', 'These', 'machines', ',', 'trying', 'to', 'replace', 'human', 'being', '##s', '.', '.', '.', 'But', 'they', 'will', 'never', 'have', 'the', 'one', 'thing', 'that', 'makes', 'each', 'of', 'us', 'special', 'and', 'unique', ',', 'soul', '##s', '.', '[SEP]'], ['[CLS]', 'In', '##e', '##quality', 'is', 'efficient', 'as', 'per', 'new', 'e', '##cono', '##mist', '##s', '.', 'Large', 'corporations', 'should', 'become', 'huge', ',', 'and', 'une', '##mployment', 'growth', 'helps', 'develop', 'sur', '##plus', '.', 'This', 'is', 'a', 'new', 'normal', '.', '[SEP]'], ['[CLS]', 'There', 'should', 'be', 'universal', 'basic', 'income', ',', 'when', 'I', 'say', 'universal', 'i', 'mean', 'whole', 'world', 'not', 'just', 'America', '[SEP]'], ['[CLS]', 'I', 'am', 'a', 'really', 'ama', '##zed', 'by', 'AI', '.', 'It', 'is', 'writing', 'codes', ',', 'genera', '##ting', 'designs', ',', 'and', 'will', 'be', 'able', 'to', 'run', 'simulation', '##s', 'soon', '.', 'I', 'am', 'wo', '##rri', '##ed', 'about', 'my', 'job', 'too', 'even', 'though', 'i', 'am', 'making', 'AI', 'to', 'do', 'all', 'that', 'st', '##uff', '[SEP]']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = []\n",
        "for i in tokenized_data:\n",
        "  ids = tokenizer.convert_tokens_to_ids(i)\n",
        "  input_ids.append(ids)\n",
        "\n",
        "print(input_ids[0])\n",
        "\n",
        "max_len = 128\n",
        "input_ids = pad_sequences(input_ids, maxlen=max_len, dtype='long', truncating='post', padding='post')\n",
        "\n",
        "attention_masks = []\n",
        "\n",
        "for ids in input_ids:\n",
        "  ids_mask = []\n",
        "  for id in ids:\n",
        "      masked = float(id>0)\n",
        "      ids_mask.append(masked)\n",
        "  attention_masks.append(ids_mask)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcj9LPFsfegq",
        "outputId": "08287b72-7837-40e6-8773-05dd98bd5962"
      },
      "id": "tcj9LPFsfegq",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 15946, 21535, 11942, 136, 133, 33989, 135, 71426, 10115, 111, 108, 11303, 132, 188, 11951, 12820, 13172, 16863, 42671, 14796, 10114, 14325, 11231, 10111, 10347, 54214, 10169, 15306, 136, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_pSu8X3fyQD",
        "outputId": "b4441c7b-0558-408b-fdd0-921c50535ef8"
      },
      "id": "p_pSu8X3fyQD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1082, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_label = np.array(sentiment[:1082])\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    input_ids, train_label, random_state=42, test_size=0.01)\n",
        "\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks,\n",
        "                                                       input_ids,\n",
        "                                                       random_state=42,\n",
        "                                                       test_size=0.01)\n",
        "\n",
        "X_train_tune = X_train\n",
        "y_train_tune = y_train\n",
        "X_val_tune = X_val\n",
        "y_val_tune = y_val\n",
        "\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train)\n",
        "y_train_tensor = torch.tensor(y_train)\n",
        "train_masks = torch.tensor(train_masks)\n",
        "X_val_tensor = torch.tensor(X_val)\n",
        "y_val_tensor = torch.tensor(y_val)\n",
        "validation_masks = torch.tensor(validation_masks)\n",
        "\n"
      ],
      "metadata": {
        "id": "1m546T6wgENY"
      },
      "id": "1m546T6wgENY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq17CTACg2qL",
        "outputId": "f54c36c0-59ba-4ef7-cab4-15d13e2ff677"
      },
      "id": "aq17CTACg2qL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U accelerate"
      ],
      "metadata": {
        "id": "GWtXjYCXhjkJ"
      },
      "id": "GWtXjYCXhjkJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -U transformers"
      ],
      "metadata": {
        "id": "N19_Z_B-hlYe"
      },
      "id": "N19_Z_B-hlYe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1082\n",
        "train = TensorDataset(X_train_tensor, train_masks, y_train_tensor)\n",
        "train_sampler = RandomSampler(train)\n",
        "\n",
        "val = TensorDataset(X_val_tensor, validation_masks, y_val_tensor)\n",
        "val_sampler = SequentialSampler(val)\n",
        "\n",
        "\n",
        "# test = TensorDataset(X_test_tensor, test_masks, y_test_tensor)\n",
        "# test_sampler = RandomSampler(test)\n",
        "\n",
        "train_dataloader = DataLoader(train, sampler=train_sampler, batch_size=batch_size)\n",
        "val_dataloader = DataLoader(val, sampler=val_sampler, batch_size=batch_size)\n",
        "# test_dataloader = DataLoader(test, sampler=test_sampler, batch_size=batch_size)\n",
        "\n",
        "train_docs, val_docs, train_labels, val_labels = train_test_split(\n",
        "    text_comments,\n",
        "    sentiment[:1082],\n",
        "    test_size=.01\n",
        ")\n"
      ],
      "metadata": {
        "id": "4KRu2C-IsqMN"
      },
      "id": "4KRu2C-IsqMN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train = TensorDataset(X_train_tensor)\n",
        "# train_sampler = RandomSampler(train)\n",
        "\n",
        "# train_dataloader = DataLoader(train, sampler=train_sampler, batch_size=1082)\n",
        "# train_docs = text_comments\n",
        "# from transformers import BertTokenizerFast\n",
        "# train_docs, _, _, _ = train_test_split(text_comments, sentiment[:1082], test_size=.01)"
      ],
      "metadata": {
        "id": "5m8oa8rwg_Gh"
      },
      "id": "5m8oa8rwg_Gh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jH8Nm_CimqZt",
        "outputId": "8a432294-ba92-46ef-ce6b-1e8348528eac"
      },
      "id": "jH8Nm_CimqZt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1071"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Cord19Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = Cord19Dataset(train_docs, sentiment[:1082])"
      ],
      "metadata": {
        "id": "irS7RGLoojqg"
      },
      "id": "irS7RGLoojqg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_measure(y_pred, y):\n",
        "    pred_flattened = np.argmax(y_pred, axis=1).flatten()\n",
        "    y_flattened = y.flatten()\n",
        "    return np.sum(pred_flattened == y_flattened) / len(y_flattened)"
      ],
      "metadata": {
        "id": "VSGDeskImnuD"
      },
      "id": "VSGDeskImnuD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForMaskedLM\n",
        "model = BertForMaskedLM.from_pretrained(f'bert_twitter')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0tYjJTJusEG",
        "outputId": "ceb2d4d1-323f-4e2f-abb3-9ca6d3241624"
      },
      "id": "k0tYjJTJusEG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert_twitter and are newly initialized: ['cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(f'bert_twitter').to(device)\n",
        "model.bert.load_state_dict(model.bert.state_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHmWU4oFu6R_",
        "outputId": "5d94af2a-7699-4de6-8d08-fc7ad62bbd8d"
      },
      "id": "WHmWU4oFu6R_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "for step, batch in enumerate(train_dataloader):\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "# model.eval()\n",
        "\n",
        "# 배치를 GPU에 넣음\n",
        "batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "# 배치에서 데이터 추출\n",
        "b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "# 그래디언트 계산 안함\n",
        "with torch.no_grad():\n",
        "  # Forward 수행\n",
        "  outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask)\n",
        "\n",
        "# 로스 구함\n",
        "logits = outputs[0]\n",
        "\n",
        "# CPU로 데이터 이동\n",
        "logits = logits.detach().cpu().numpy()\n",
        "label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "# # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
        "# tmp_eval_accuracy = accuracy_measure(logits, label_ids)\n",
        "# eval_accuracy += tmp_eval_accuracy\n",
        "# nb_eval_steps += 1"
      ],
      "metadata": {
        "id": "uIKfb-_moyRF"
      },
      "id": "uIKfb-_moyRF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_flattened = np.argmax(logits, axis=1).flatten()\n",
        "pred_flattened"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQAsqgSRllvW",
        "outputId": "a7a56179-588f-4e4e-f725-28e700c97f75"
      },
      "id": "XQAsqgSRllvW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizerFast, TFBertModel, BertForSequenceClassification\n",
        "\n",
        "model_name = \"bert-base-multilingual-cased\"\n",
        "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
        "model = BertForSequenceClassification.from_pretrained('bert_twitter')\n"
      ],
      "metadata": {
        "id": "heV-8rL0S3Zt"
      },
      "id": "heV-8rL0S3Zt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step, batch in enumerate(train_dataloader):\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "model.eval()\n",
        "# 배치를 GPU에 넣음\n",
        "batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "# 배치에서 데이터 추출\n",
        "b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "# 그래디언트 계산 안함\n",
        "with torch.no_grad():\n",
        "  # Forward 수행\n",
        "  outputs = model(b_input_ids,\n",
        "                        token_type_ids=None,\n",
        "                        attention_mask=b_input_mask)\n",
        "# 로스 구함\n",
        "logits = outputs[0]\n",
        "\n",
        "# CPU로 데이터 이동\n",
        "logits = logits.detach().cpu().numpy()\n",
        "label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "pred_flattened = np.argmax(logits, axis=1).flatten()\n",
        "pred_flattened"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zU6fcGrDIz4G",
        "outputId": "9facd059-38d0-4b57-dd89-d6af2e13e573"
      },
      "id": "zU6fcGrDIz4G",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "528261c4c39f4d44ab46f784a914574c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_840b7ebb5fed494ea917fd9f9283a187",
              "IPY_MODEL_351c11a2a1484d45b7a56284b69b0631",
              "IPY_MODEL_24105b2a1347429ca18833d67b78cbc8"
            ],
            "layout": "IPY_MODEL_e8338060cd624ab3a16ecb412f237760"
          }
        },
        "840b7ebb5fed494ea917fd9f9283a187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_488a8fbdd9b94cfdba1323712744eb23",
            "placeholder": "​",
            "style": "IPY_MODEL_d868cc8b543f4a78ae6a1519e6ecfabf",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "351c11a2a1484d45b7a56284b69b0631": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3b0d2248a704fb3983bd26636839227",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b56d41cb236b426791713b2f28462a9c",
            "value": 49
          }
        },
        "24105b2a1347429ca18833d67b78cbc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93a68eb293cf4581b2785f7a28d9a0c0",
            "placeholder": "​",
            "style": "IPY_MODEL_bf5108769244495daa4d5c99c40afc1e",
            "value": " 49.0/49.0 [00:00&lt;00:00, 1.89kB/s]"
          }
        },
        "e8338060cd624ab3a16ecb412f237760": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "488a8fbdd9b94cfdba1323712744eb23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d868cc8b543f4a78ae6a1519e6ecfabf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3b0d2248a704fb3983bd26636839227": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b56d41cb236b426791713b2f28462a9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93a68eb293cf4581b2785f7a28d9a0c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf5108769244495daa4d5c99c40afc1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8b52ecd29fc4dca97cf3182ee15175d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4a43f2d33e44da6887819dea6f51484",
              "IPY_MODEL_3ebcd04cb9ba49f4bc8d82a07e966ee2",
              "IPY_MODEL_c3c444635c4846bbb31c14a6e4f355ad"
            ],
            "layout": "IPY_MODEL_0c15f018e8c24dcab945e09e729b96fc"
          }
        },
        "e4a43f2d33e44da6887819dea6f51484": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01d459281fad4a868534321cf7f9d339",
            "placeholder": "​",
            "style": "IPY_MODEL_f649300ed45b48c6be5d8dd3fcd79be2",
            "value": "vocab.txt: 100%"
          }
        },
        "3ebcd04cb9ba49f4bc8d82a07e966ee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ae446c5c8ea4b7d9647eac7e92ed1c2",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa5ed9d8a7b543cf90e387a34e766225",
            "value": 995526
          }
        },
        "c3c444635c4846bbb31c14a6e4f355ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39df54c9df0e4b69a2aaa3fbf95dd8ad",
            "placeholder": "​",
            "style": "IPY_MODEL_4aa8865ba4f043429ef322ccd0073571",
            "value": " 996k/996k [00:00&lt;00:00, 3.87MB/s]"
          }
        },
        "0c15f018e8c24dcab945e09e729b96fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01d459281fad4a868534321cf7f9d339": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f649300ed45b48c6be5d8dd3fcd79be2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ae446c5c8ea4b7d9647eac7e92ed1c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa5ed9d8a7b543cf90e387a34e766225": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39df54c9df0e4b69a2aaa3fbf95dd8ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4aa8865ba4f043429ef322ccd0073571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f87661bce9514bafbbdeedb7ac4323d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1ea5dcd79c242d2a14d32479405c20f",
              "IPY_MODEL_3886ff12aebe48b98d56f0cae2ab349e",
              "IPY_MODEL_f134b1f6e6a841609560e788c344812f"
            ],
            "layout": "IPY_MODEL_4687ce12cd4845a39ce3801c26848a4f"
          }
        },
        "b1ea5dcd79c242d2a14d32479405c20f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30f5526ad6d44460b5fe6f81e64129a8",
            "placeholder": "​",
            "style": "IPY_MODEL_40e0326f40c3461f8d02219a4683a5bd",
            "value": "tokenizer.json: 100%"
          }
        },
        "3886ff12aebe48b98d56f0cae2ab349e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4d607b795b348c287deee1737772128",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c3beb9b76ec45c2a649ac1beebfcf28",
            "value": 1961828
          }
        },
        "f134b1f6e6a841609560e788c344812f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df0c8e8c9f8343e2b6951cd6e09e24de",
            "placeholder": "​",
            "style": "IPY_MODEL_9c6d57bcf97f4ead9878fe9aa5398462",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 41.0MB/s]"
          }
        },
        "4687ce12cd4845a39ce3801c26848a4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30f5526ad6d44460b5fe6f81e64129a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40e0326f40c3461f8d02219a4683a5bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4d607b795b348c287deee1737772128": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c3beb9b76ec45c2a649ac1beebfcf28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df0c8e8c9f8343e2b6951cd6e09e24de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c6d57bcf97f4ead9878fe9aa5398462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a424265667546bc9600df7f1067aab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c3c8b5197ae74a10a6f7c67c3576b37f",
              "IPY_MODEL_f8bbc301d5974879835d4d058d481502",
              "IPY_MODEL_d38c6ac71453418889a0bfd7cf0fe8a9"
            ],
            "layout": "IPY_MODEL_5a95c7b98f67474bb12331edb1ecabe9"
          }
        },
        "c3c8b5197ae74a10a6f7c67c3576b37f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd24232fa5f84ffcb96b52a26ff56e78",
            "placeholder": "​",
            "style": "IPY_MODEL_0420692fd4ec4661b445cea1f42e2695",
            "value": "config.json: 100%"
          }
        },
        "f8bbc301d5974879835d4d058d481502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10df7a3b1ba14d0a8c8de2055d0f16d1",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_36e8ec5a160244a98fe84a2402ec4753",
            "value": 625
          }
        },
        "d38c6ac71453418889a0bfd7cf0fe8a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aab4ed46c1c942ebb82c77b3f6957dbf",
            "placeholder": "​",
            "style": "IPY_MODEL_adf730615ce445ea83ae535156f5bdd8",
            "value": " 625/625 [00:00&lt;00:00, 20.1kB/s]"
          }
        },
        "5a95c7b98f67474bb12331edb1ecabe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd24232fa5f84ffcb96b52a26ff56e78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0420692fd4ec4661b445cea1f42e2695": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10df7a3b1ba14d0a8c8de2055d0f16d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36e8ec5a160244a98fe84a2402ec4753": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aab4ed46c1c942ebb82c77b3f6957dbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adf730615ce445ea83ae535156f5bdd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}